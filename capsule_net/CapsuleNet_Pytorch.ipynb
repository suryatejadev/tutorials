{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capsule Network in Pytorch  \n",
    "\n",
    "## Brief notes on capsnet\n",
    "### Drawbacks of CNNs\n",
    "1. Pose (Orientational) and relative spatial relationships are not learnt in CNNs. \"Internal data representation of a convolutional neural network does not take into account important spatial hierarchies between simple and complex objects.\"  \n",
    "2. \"CNN approach to solve this issue is to use max pooling or successive convolutional layers that reduce spacial size of the data flowing through the network and therefore increase the “field of view” of higher layer’s neurons, thus allowing them to detect higher order features in a larger region of the input image.\" But pooling loses information.  \n",
    "\n",
    "### Motivation for Capsule Networks\n",
    "1. **Rendering in graphics**: Arrays of geometrical objects and matrices that represent relative positions and orientation of the objects are stored. In rendering, a software converts this representation into an image.  \n",
    "2. Hinton argues the brain does the opposite. \n",
    "3. **Inverse graphics**: From visual information received by eyes, they deconstruct a hierarchical representation of the world around us and try to match it with already learned patterns and relationships stored in the brain. This is how recognition happens. And the key idea is that representation of objects in the brain does not depend on view angle.  \n",
    "4. How to model the hierarchial relations in ANN?  \n",
    "    - Pose: In graphices, relations between objects is represented using pose (translation + rotation).  \n",
    "    - \"Hinton argues that in order to correctly do classification and object recognition, it is important to preserve hierarchical pose relationships between object parts. This is the key intuition that will allow you to understand why capsule theory is so important. It incorporates relative relationships between objects and it is represented numerically as a 4D pose matrix.\"\n",
    "\n",
    "### Advantages\n",
    "1. CapsuleNets easily identify objects independent of the **views** because the relationships of 3D objects in the image are explicitly modeled, but for a CNN this is very hard.  \n",
    "2. CapsuleNets can learn with much less data than CNN.  \n",
    "\n",
    "### Capsules\n",
    "1. Capsule Nets were there decades ago, but there was no way to learn the model until the paper \"dynamic routing between capsules\".  \n",
    "2. **Viewpoint Invariance**: Detection of a particular visual entity in an image should be invariant of it's pose, lighting and deformation.\n",
    "    - **Problem with CNN**: To achieve viewpoint invariance, CNNs use maxpooling. This makes it slightly viewpoint invariant. But pooling loses lot of information, and the relative spatial relations between features is not learnt.  \n",
    "    - **Solution? Use capsules**: \"*Each capsule learns to recognize an implicitly defined visual entity over a limited domain of viewing conditions and deformations and it **outputs both the probability that the entity is present within its limited domain and a set of “instantiation parameters” that may include the precise pose, lighting and deformation of the visual entity relative to an implicitly defined canonical version of that entity**.*\"\n",
    "    - **Ideal scenario of capsules**: Irrespective of the view of the visual entity, the probability should remain constant, while the instantiation parameters change depending on the location of the entity relative to the intrinsic coordinates of that entity - they are \"equivariant\".  \n",
    "\n",
    "#### Working of a capsule\n",
    "Consider lower level capsules as eyes, nose, mouth and higher level capsules as face, hair.  \n",
    "1. **Matrix multiplication of input vectors**:\n",
    "    - Outputs of lower level capsules are multiplied with weight matrics.\n",
    "    - The weights encode spatial and other relations between the lower level feature and the higher level feature.\n",
    "    - For example: given the output of nose, we get the probability of there being a face and its location given the nose.  \n",
    "2. **Scalar weighting of input vectors**:  \n",
    "     - The lower capsule should decide to which higher capsule it will send its output to.\n",
    "     - It decides using **dynamic routing**. \n",
    "     - Example: eyes, nose and mouth predict that there is a face with high probability, and the predicted face locations are close. However, the corresponding outputs for hair are low probability and farther locations since they don't impact hair as much as they influence face. So, the lower capsule updates the weights such that weight corresponding to face is high and hair is low.  \n",
    "3. **Sum of weighted Input Vectors**  \n",
    "4. **Squashing**: If s<sub>j</sub> is the output of the j<sup>th</sup> capsule, then non linearity is applied to it by squashing, such that the direction is not changed.\n",
    "\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
