{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Tutorial  \n",
    "\n",
    "## Notes:  \n",
    "1. The sequential model and the data should be assigned a device.  \n",
    "    - model.to(device)  \n",
    "    - data.to(device)  \n",
    "2. For every batch, model.zero_grad() should be used to set the gradients to zero, as pytorch accumulated the gradients.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Notes **  \n",
    "1. **Autograd**  \n",
    "    - 2 important classes: Tensor and Function  \n",
    "    - Tensor and Function are interconnected and build up an acyclic graph, that encodes a complete history of computation. Each variable has a .grad_fn attribute that references a Function that has created the Tensor \n",
    "    - For grad(), if its not a scalar, you need to specify a gradient argument that is a tensor of matching shape \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Since x is an independent variable, it has grad_fn = None\n",
      "Since y is dependent on x, it has grad_fn = <AddBackward1 object at 0x7fd8174f2048>\n",
      "backward prints dy/dx, so dy/dx=2x\n",
      "tensor([[ 3.,  3.],\n",
      "        [ 3.,  3.]])\n",
      "backward prints dy/dz, so dy/dz=3x\n",
      "tensor([[ 6.,  6.],\n",
      "        [ 6.,  6.]])\n"
     ]
    }
   ],
   "source": [
    "# Autograd basics\n",
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "z = torch.ones(2, 2, requires_grad=True)\n",
    "print('Since x is an independent variable, it has grad_fn =',x.grad_fn)\n",
    "y = x**2 + z**3\n",
    "print('Since y is dependent on x, it has grad_fn =',y.grad_fn)\n",
    "print('backward prints dy/dx, so dy/dx=2x')\n",
    "y.backward(gradient = z, retain_graph=True)\n",
    "print(z.grad)\n",
    "print('backward prints dy/dz, so dy/dz=3x')\n",
    "y.backward(gradient = z)\n",
    "print(z.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Neural Nets**  \n",
    "1. when we call loss.backward(), the whole graph is differentiated w.r.t. the loss, and all Tensors in the graph that has requres_grad=True will have their .grad Tensor accumulated with the gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Neural Net\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)\n",
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())  # conv1's .weight\n",
    "output = net(input)\n",
    "target = torch.arange(1, 11)  # a dummy target, for example\n",
    "target = target.view(1, -1)  # make it the same shape as output\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(output, target)\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convTranspose2D  \n",
    "\n",
    "1. In pytorch, zero padding in convTranspose2d is done on the right and bottom sides only.  \n",
    "2. With padding=1, 1 -> ((1,0),(0,0))  \n",
    "3. **a1 = conv2d(b1), a2 = convTranspose2D(b2) ; if shapes of b2=a1, then shapes of a2=b1, ie., to know what will be the output shape of a convTranspose2D on X, just see doing conv2d on what shape would lead to the shape of X. **  \n",
    "\n",
    "Examples for input and output of convTranspose2d:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padding=0\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "   ConvTranspose2d-1             [-1, 64, 4, 4]          102400\n",
      "================================================================\n",
      "Total params: tensor(1.0240e+05)\n",
      "Trainable params: tensor(1.0240e+05)\n",
      "Non-trainable params: tensor(0)\n",
      "----------------------------------------------------------------\n",
      "\n",
      "\n",
      "padding=1\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "   ConvTranspose2d-1             [-1, 64, 2, 2]          102400\n",
      "================================================================\n",
      "Total params: tensor(1.0240e+05)\n",
      "Trainable params: tensor(1.0240e+05)\n",
      "Non-trainable params: tensor(0)\n",
      "----------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "model = nn.Sequential(nn.ConvTranspose2d(100, 64, 4, 1, 0, bias=False))\n",
    "noise = torch.randn(4, 100, 1, 1)\n",
    "print('padding=0')\n",
    "summary(model, (100,1,1))\n",
    "print('\\n')\n",
    "\n",
    "model = nn.Sequential(nn.ConvTranspose2d(100, 64, 4, 1, 1, bias=False))\n",
    "noise = torch.randn(4, 100, 1, 1)\n",
    "print('padding=1')\n",
    "summary(model, (100,1,1))\n",
    "print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
